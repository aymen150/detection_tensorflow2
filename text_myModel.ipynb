{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image():\n",
    "    Liste =  []\n",
    "    path = define_path()\n",
    "    for path_dataset in path :\n",
    "        for file_name in os.listdir(path_dataset)[:3]:\n",
    "            if file_name.split(\".\")[-1].lower() in {\"jpeg\", \"jpg\", \"png\"}:\n",
    "                x = str (path_dataset + file_name)\n",
    "                Liste.append(x)\n",
    "                print(file_name)               \n",
    "    return Liste\n",
    "\n",
    "\n",
    "def define_path():\n",
    "        return [\"Dataset/test/Traffic sign/\",\"Dataset/test/Stop sign/\",\"Dataset/test/Traffic light/\",\"Dataset/test/Car/\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage(img,rec):\n",
    "    r,g,b = 255 , 0,0\n",
    "    img = cv2.imread(img)\n",
    "    for ax in rec:   \n",
    "                cv2.rectangle(img[0], (ax[-2],ax[-1]),(ax[-4],ax[-3]), (b, g, r), 1)\n",
    "    \n",
    "    cv2.imshow(\"window_name\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_int_to_text(row_label):\n",
    "    if row_label == 1:\n",
    "        return 'Stop sign'\n",
    "    if row_label == 2 :\n",
    "        return 'Car'\n",
    "    if row_label == 3:\n",
    "        return 'Traffic sign'\n",
    "    if row_label == 4:\n",
    "        return 'Traffic light'\n",
    "    else:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "45f9b594fd32feb1.jpg\n01e835e68b6af93d.jpg\ncd2f0a3e2c35714e.jpg\nd71a9e82a6cb405e.jpg\n78066a4752bc11fe.jpg\n20263e31e7f52ccf.jpg\n6da98e451ccc6836.jpg\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATHS = load_image()\n",
    "PATH_TO_MODEL = 'exported-models_1_my_model/saved_model/'\n",
    "PATH_TO_LABELS = 'training/label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done! Took 10.04129958152771 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running inference for Dataset/test/Traffic sign/45f9b594fd32feb1.jpg... \n",
      "image  1\n",
      "Car 0.30667096\n",
      "Stop sign 0.29380175\n",
      "Traffic sign 0.2807417\n",
      "Car 0.23168895\n",
      "Done\n",
      "Running inference for Dataset/test/Traffic sign/01e835e68b6af93d.jpg... \n",
      "image  2\n",
      "Car 0.30667096\n",
      "Stop sign 0.29380175\n",
      "Traffic sign 0.2807417\n",
      "Car 0.23168895\n",
      "Done\n",
      "Running inference for Dataset/test/Stop sign/cd2f0a3e2c35714e.jpg... \n",
      "image  3\n",
      "Car 0.30667096\n",
      "Stop sign 0.29380175\n",
      "Traffic sign 0.2807417\n",
      "Car 0.23168895\n",
      "Done\n",
      "Running inference for Dataset/test/Stop sign/d71a9e82a6cb405e.jpg... \n",
      "image  4\n",
      "Car 0.30667096\n",
      "Stop sign 0.29380175\n",
      "Traffic sign 0.2807417\n",
      "Car 0.23168895\n",
      "Done\n",
      "Running inference for Dataset/test/Traffic light/78066a4752bc11fe.jpg... \n",
      "image  5\n",
      "Car 0.30667096\n",
      "Stop sign 0.29380175\n",
      "Traffic sign 0.2807417\n",
      "Car 0.23168895\n",
      "Done\n",
      "Running inference for Dataset/test/Car/20263e31e7f52ccf.jpg... \n",
      "image  6\n",
      "Car 0.30667096\n",
      "Stop sign 0.29380175\n",
      "Traffic sign 0.2807417\n",
      "Car 0.23168895\n",
      "Done\n",
      "Running inference for Dataset/test/Car/6da98e451ccc6836.jpg... \n",
      "image  7\n",
      "Car 1.0\n",
      "Traffic sign 0.9869466\n",
      "Car 0.42794204\n",
      "Car 0.30667096\n",
      "Stop sign 0.29380175\n",
      "Traffic sign 0.2807417\n",
      "Car 0.23168895\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "a=0\n",
    "def load_image_into_numpy_array(path):\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "#IMAGE_PATHS = ['img.jpg']\n",
    "for image_path in IMAGE_PATHS:\n",
    "    a=a+1\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "    image_np = load_image_into_numpy_array(image_path)\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    print(\"\\nimage \" , a)\n",
    "    for i in range(len(detections['detection_scores'])):\n",
    "        if detections['detection_scores'][i] > 0.23 :\n",
    "            print( class_int_to_text(detections['detection_classes'][i]), detections['detection_scores'][i])\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.23,\n",
    "          agnostic_mode=False)\n",
    "    \n",
    "    ####### choise  1: sav or  2 : show\n",
    "    #1 sav\n",
    "    plt.figure()\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    print('Done')\n",
    "    plt.savefig(\"txt\"+str(a)+\".jpg\")\n",
    "    #2 show\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_np_with_detections)\n",
    "    cv2.imshow(\"window_name\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \"\"\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage(IMAGE_PATHS,detections['detection_boxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "type(detections['detection_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9869466"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "detections['detection_scores'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}